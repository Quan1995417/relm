{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extreme learning machines\n",
    "***\n",
    "*Universidade Federal de Minas Gerais*  \n",
    "*Introdução à Inteligência Computacional*  \n",
    "*Autores: Alvaro Lemos e Felipe Carvalho*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELM theory\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EML implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#loading datasets\n",
    "from sklearn.datasets import load_boston, load_breast_cancer, california_housing\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "\n",
    "#loading linear models for the output layer of the ELM\n",
    "from sklearn.linear_model import ElasticNet, Lasso, Ridge, LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, Perceptron\n",
    "\n",
    "#misc functions from sklearn\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.grid_search import ParameterGrid\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Activation functions for the hidden layer of the ELM\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ELMRegressor:\n",
    "\n",
    "    def __init__(self, n_hidden, regularizer = None, alpha = 1.0, **kwargs):\n",
    "        self.n_hidden = n_hidden\n",
    "        self.alpha = alpha\n",
    "        self.activation_func = sigmoid\n",
    "\n",
    "        if regularizer:\n",
    "            self.regularizer = regularizer.lower()\n",
    "        else:\n",
    "            self.regularizer = regularizer\n",
    "\n",
    "        if not self.regularizer:\n",
    "            self.model = LinearRegression(n_jobs=-1)\n",
    "        elif self.regularizer == 'lasso' or self.regularizer == 'l1':\n",
    "            self.model = Lasso(alpha=self.alpha, **kwargs)\n",
    "        elif self.regularizer == 'ridge' or self.regularizer == 'l2':\n",
    "            self.model = Ridge(alpha=self.alpha, **kwargs)\n",
    "        elif self.regularizer == 'elasticnet' or self.regularizer == 'l1l2':\n",
    "            self.model = ElasticNet(alpha=self.alpha, **kwargs)\n",
    "        else:\n",
    "            raise ValueError('{} regularization invalid'.format(self.regularizer))\n",
    "\n",
    "    def _initialize_hidden_layer(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.W_ = np.random.randn(n_features, self.n_hidden)\n",
    "\n",
    "\n",
    "    def _project_features(self, X):\n",
    "        G = self.activation_func(np.dot(X, self.W_))\n",
    "        return G\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self._initialize_hidden_layer(X)\n",
    "        G = self._project_features(X)\n",
    "        self.model.fit(G, y)    \n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        G = self._project_features(X)\n",
    "        return self.model.predict(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_boston_dataset():\n",
    "    boston = load_boston()\n",
    "    X = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "    X = one_hot_encode_column(X, 'CHAS')\n",
    "    y = boston.target.reshape(-1, 1)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def one_hot_encode_column(X, col):\n",
    "    chas_encoded = LabelEncoder().fit_transform(X[col]).reshape(-1, 1)\n",
    "    chas_dummy = OneHotEncoder(sparse=False).fit_transform(chas_encoded)\n",
    "    return pd.concat([X.drop(col, axis=1), pd.DataFrame(chas_dummy)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_val_split(X, y, train_index, val_index):\n",
    "    X_train = X.iloc[train_index, :]\n",
    "    X_val = X.iloc[val_index, :]\n",
    "    y_train = y[train_index, :]\n",
    "    y_val = y[val_index, :]\n",
    "\n",
    "    return X_train, X_val, y_train, y_val    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    ('Boston Housing', get_boston_dataset)\n",
    "]\n",
    "\n",
    "models = [\n",
    "    {\n",
    "        'name': 'ELM',\n",
    "        'model': ELMRegressor,\n",
    "        'regularization': None,\n",
    "        'grid': { 'n_hidden': [100, 500, 1000, 5000, 10000] }\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'name': 'ELM Ridge',\n",
    "        'model': ELMRegressor,\n",
    "        'regularization': 'ridge',\n",
    "        'grid': { 'alpha': [0.001, 0.01, 0.1, 1], 'n_hidden': [100, 500, 1000, 5000, 10000] }\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'name': 'ELM Lasso',\n",
    "        'model': ELMRegressor,\n",
    "        'regularization': 'lasso',\n",
    "        'grid': { 'alpha': [0.001, 0.01, 0.1, 1], 'n_hidden': [100, 500, 1000, 5000, 10000] }\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'name': 'ELM ElasticNet',\n",
    "        'model': ELMRegressor,\n",
    "        'regularization': 'ridge',\n",
    "        'grid': { 'alpha': [0.001, 0.01, 0.1, 1], 'n_hidden': [100, 500, 1000, 5000, 10000] }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "results = []\n",
    "\n",
    "for dataset_name, dataset_getter in datasets:\n",
    "    X, y = dataset_getter()\n",
    "    X_cv, X_test, y_cv, y_test = train_test_split(X, y)\n",
    "\n",
    "    for model_info in models:\n",
    "        param_grid = ParameterGrid(model_info['grid'])\n",
    "\n",
    "        grid_results = []\n",
    "        for params in param_grid:\n",
    "\n",
    "            kf = KFold(n_splits=5, random_state=1)\n",
    "            rmses = []\n",
    "            for train_index, val_index in kf.split(X_cv):\n",
    "                X_cv_train, X_cv_val, y_cv_train, y_cv_val = \\\n",
    "                    train_val_split(X_cv, y_cv, train_index, val_index)\n",
    "\n",
    "                scaler = StandardScaler()\n",
    "                scaler.fit(X_cv_train)\n",
    "                X_cv_train = scaler.transform(X_cv_train)\n",
    "                X_cv_val = scaler.transform(X_cv_val)\n",
    "\n",
    "                model = model_info['model'](regularizer=model_info['regularization'], **params)\n",
    "                model.fit(X_cv_train, y_cv_train)\n",
    "                y_cv_pred = model.predict(X_cv_val)\n",
    "                rmse = np.sqrt(mean_squared_error(y_cv_val, y_cv_pred))\n",
    "                rmses.append(rmse)\n",
    "\n",
    "            grid_results.append((np.mean(rmses), params))\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_cv)\n",
    "        X_cv_scaled = scaler.transform(X_cv)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        best_params = sorted(grid_results)[0][1]\n",
    "\n",
    "        best_params_results = []\n",
    "        for _ in range(5):\n",
    "            model = model_info['model'](regularizer=model_info['regularization'], **best_params)\n",
    "            model.fit(X_cv_scaled, y_cv)\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "            rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "            best_params_results.append(rmse)\n",
    "        best_mean_rmse = np.mean(best_params_results)\n",
    "\n",
    "        if model_info['name'] == 'ELM':\n",
    "            best_alpha = '-'\n",
    "        else:\n",
    "            best_alpha = best_params['alpha']\n",
    "        best_n_hidden = best_params['n_hidden']\n",
    "\n",
    "        results.append((dataset_name, model_info['name'], best_mean_rmse, best_n_hidden, best_alpha))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results, columns=['Dataset', 'Model', 'RMSE', 'Best # Nodes', 'Best alpha'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
